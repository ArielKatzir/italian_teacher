{"cells":[{"cell_type":"markdown","metadata":{"id":"mFalqG5F_A71"},"source":["# GRPO Training for Italian Exercise Generator"]},{"cell_type":"markdown","metadata":{"id":"J4B78ZgA_A73"},"source":["## Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32575,"status":"ok","timestamp":1761324995188,"user":{"displayName":"Ariel Katzir","userId":"13010007500212358071"},"user_tz":-60},"id":"cCJu42Bk_A74","outputId":"5b68130f-958a-4185-9ef2-78e37ec8d798"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Changed directory to: /content/drive/MyDrive/Colab Notebooks/italian_teacher\n","Collecting it-core-news-sm==3.8.0\n","  Using cached https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.8.0/it_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('it_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n","Requirement already satisfied: anthropic in /usr/local/lib/python3.12/dist-packages (0.71.0)\n","Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (0.33.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.11.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.9.0)\n","Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.17.0)\n","Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.11.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (2.11.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.15.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.11)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n","\n","--- Environment Setup ---\n","PyTorch version: 2.8.0+cu126\n","CUDA available: True\n","GPU: NVIDIA A100-SXM4-80GB\n"]}],"source":["# --- Cell 1: Setup and Imports ---\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Navigate to your project directory\n","# Make sure this path is correct for your Google Drive setup\n","import os\n","project_path = '/content/drive/MyDrive/Colab Notebooks/italian_teacher'\n","os.chdir(project_path)\n","print(f\"Changed directory to: {os.getcwd()}\")\n","\n","# Install dependencies (now includes google-generativeai for Gemini API)\n","!pip install -q transformers trl accelerate peft datasets spacy sentence-transformers bitsandbytes json5 openai google-generativeai tqdm nest_asyncio\n","!python -m spacy download it_core_news_sm\n","!pip install anthropic groq\n","\n","# Standard library imports\n","import json\n","import random\n","from getpass import getpass\n","\n","# Third-party imports\n","import torch\n","from datasets import Dataset\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from trl import GRPOConfig, GRPOTrainer\n","\n","# Local module imports\n","from src.rl.multi_reward_async import create_async_multi_reward\n","from src.rl.prompt_formatter import format_prompt_with_chat_template\n","from src.rl.reward_function import ExerciseRewardFunction\n","\n","# Environment setup\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","print(\"\\n--- Environment Setup ---\")\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"t_HTIkZ0_A75","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761324995293,"user_tz":-60,"elapsed":107,"user":{"displayName":"Ariel Katzir","userId":"13010007500212358071"}},"outputId":"76546175-f90f-455e-d4f3-ecb474b7be16"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Configuration loaded.\n","   Base model: ./models/italian_v8_grpo_round2\n","   Output directory: ./models/TeacherPet_italian_grpo\n","   Training samples: 2000\n","   Fluency scorer: Enabled (rule-based)\n"]}],"source":["# --- Cell 2: Configuration ---\n","# All training parameters are here for easy modification.\n","\n","BASE_MODEL_PATH = \"./models/italian_v8_grpo_round2\"  # Input model for this training run\n","OUTPUT_DIR = \"./models/TeacherPet_italian_grpo\"      # Where the new model will be saved\n","NUM_SAMPLES = 2000                                    # Number of training requests to use\n","RANDOM_SEED = 44                                      # Seed for reproducibility\n","\n","# Scorer settings\n","DISABLED_SCORERS = []          # No scorers disabled\n","FLUENCY_USE_LLM = False        # Use rule-based checks only (fast, free)\n","\n","# --- GRPO Configuration ---\n","grpo_config = GRPOConfig(\n","    output_dir=OUTPUT_DIR,\n","    num_train_epochs=1,\n","    per_device_train_batch_size=12,\n","    gradient_accumulation_steps=4,\n","    learning_rate=5e-6,\n","    warmup_steps=50,\n","    logging_steps=5,\n","    save_steps=100,\n","    save_total_limit=3,\n","    bf16=True,\n","    remove_unused_columns=False,\n","    report_to=\"none\",\n","\n","    # GRPO-specific generation settings\n","    num_generations=3,\n","    max_completion_length=350,\n","    temperature=0.7,\n","    generation_batch_size=24,\n","\n","    # Generation kwargs\n","    generation_kwargs={\n","      \"bos_token_id\": 128000,\n","      \"do_sample\": True,\n","      \"eos_token_id\": [128009, 128001],\n","      \"pad_token_id\": 128009,\n","      \"top_p\": 0.9,\n","      \"padding_side\": \"left\"\n","    }\n",")\n","\n","print(\"✅ Configuration loaded.\")\n","print(f\"   Base model: {BASE_MODEL_PATH}\")\n","print(f\"   Output directory: {OUTPUT_DIR}\")\n","print(f\"   Training samples: {NUM_SAMPLES}\")\n","print(f\"   Fluency scorer: {'Enabled (rule-based)' if not DISABLED_SCORERS else 'Disabled'}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"EyD8vpaC_A75","colab":{"base_uri":"https://localhost:8080/","height":743,"referenced_widgets":["a749819e3451414ebecd80adfceb88c8","925b645e39b74e55aeb0d781e28bf0fb","547ae1e792b647a9ad248387071c17ac","66d673a3cd204eb6aa59d0b41d8c0d75","feec6650cb86433c96d51603fcd5b94f","5c7f27abb2ac4f199ddc7d416da5ddb6","545119c7d2b94d6ca75bb067f082d125","873742b3a85d42219253b60c89826d0e","904c5db8dd7d4638ae46fc5fdf203ee6","88b07741ab714d53a6506b81348c525d","6ab9cbc54ba140da853e2ed97c362b75"]},"executionInfo":{"status":"ok","timestamp":1761325011838,"user_tz":-60,"elapsed":16537,"user":{"displayName":"Ariel Katzir","userId":"13010007500212358071"}},"outputId":"b1e355f4-8115-44d4-b661-4a55314e0094"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","🚀 STARTING GRPO TRAINING\n","================================================================================\n","\n","--- Loading Secrets ---\n","✅ Loading API keys from /content/drive/My Drive/.secrets.json\n","   Loaded 9 API key(s)\n","\n","--- Loading Model ---\n","Base model: ./models/italian_v8_grpo_round2\n"]},{"output_type":"stream","name":"stderr","text":["`torch_dtype` is deprecated! Use `dtype` instead!\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a749819e3451414ebecd80adfceb88c8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Model and tokenizer loaded.\n","\n","--- Preparing Training Data ---\n","Loading existing training requests from src/rl/training_requests.json...\n","✅ Loaded 2000 training requests.\n","\n","--- Initializing Reward Function ---\n","Loading spaCy model: it_core_news_sm...\n","✅ spaCy model loaded\n","Reward function will use device: cuda\n","     ✅ Gemini: 4 API key(s)\n","     ✅ OpenAI: configured\n","     ✅ Anthropic: configured\n","     ✅ Groq: configured\n","     ✅ DeepSeek: configured\n","     ✅ Cerebras: configured\n","  ✅ LLM API Handler initialized\n","     Providers: gemini, openai, anthropic, groq, deepseek, cerebras\n","     Total models: 12\n","Initializing scorers...\n","  ✅ LLM scoring enabled for cefr_alignment (batch size: 10)\n","  ✅ LLM scoring enabled for fluency (batch size: 10)\n","  ✅ LLM scoring enabled for grammar_correctness (batch size: 10)\n","  ✅ LLM scoring enabled for coherence (batch size: 10)\n","Loading sentence transformer for topic similarity...\n","✅ Sentence transformer loaded in cuda\n","  ✅ LLM topic checking enabled (OpenAI API)\n","✅ Reward function initialized. Active scorers: ['json', 'quality', 'linguistic', 'cefr', 'fluency', 'grammar', 'coherence', 'topic']\n","✅ Reward function ready.\n"]}],"source":["# --- Cell 3: Helper Functions & Main Execution ---\n","\n","def load_secrets_from_file():\n","    \"\"\"\n","    Load API keys from .secrets.json file if it exists.\n","    Checks multiple locations: Google Drive root, then current directory.\n","    \"\"\"\n","    from pathlib import Path\n","\n","    secrets_paths = [\n","        Path.home() / \"Google Drive\" / \"My Drive\" / \".secrets.json\",  # Local path\n","        Path(\"/content/drive/My Drive/.secrets.json\"),                # Colab path\n","        Path('.secrets.json')                                         # Current directory\n","    ]\n","\n","    for path in secrets_paths:\n","        if path.exists():\n","            print(f\"✅ Loading API keys from {path}\")\n","            with open(path, 'r') as f:\n","                secrets = json.load(f)\n","\n","            loaded_keys = []\n","            for key, value in secrets.items():\n","                if value and value not in [\"your-openai-key-here\", \"your-google-key-here\", \"\"]:\n","                    os.environ[key] = value\n","                    loaded_keys.append(key)\n","\n","            if loaded_keys:\n","                print(f\"   Loaded {len(loaded_keys)} API key(s)\")\n","                return True\n","\n","    print(\"⚠️  No .secrets.json found. Make sure API keys are in Colab secrets or environment.\")\n","    return False\n","\n","\n","def load_training_data(tokenizer, num_samples: int, seed: int):\n","    \"\"\"Load or generate training requests and prepare dataset.\"\"\"\n","    requests_path = \"src/rl/training_requests.json\"\n","\n","    if os.path.exists(requests_path):\n","        print(f\"Loading existing training requests from {requests_path}...\")\n","        with open(requests_path, \"r\") as f:\n","            training_requests = json.load(f)\n","    else:\n","        from src.rl.generate_training_requests import generate_training_requests\n","        print(f\"Generating {num_samples} new training requests...\")\n","        training_requests = generate_training_requests(\n","            num_requests=num_samples,\n","            output_path=requests_path\n","        )\n","\n","    print(f\"✅ Loaded {len(training_requests)} training requests.\")\n","\n","    # Format prompts\n","    prompts = [\n","        format_prompt_with_chat_template(req, tokenizer, add_examples=True)\n","        for req in training_requests\n","    ]\n","\n","    # Sample if needed\n","    if len(prompts) > num_samples:\n","        print(f\"Sampling {num_samples} requests (seed={seed})...\")\n","        random.seed(seed)\n","        random_indices = random.sample(range(len(prompts)), num_samples)\n","        prompts = [prompts[i] for i in random_indices]\n","        training_requests = [training_requests[i] for i in random_indices]\n","\n","    return Dataset.from_dict({\n","        \"prompt\": prompts,\n","        \"request\": training_requests,\n","    })\n","\n","\n","print(\"=\" * 80)\n","print(\"🚀 STARTING GRPO TRAINING\")\n","print(\"=\" * 80)\n","\n","# Load API keys\n","print(\"\\n--- Loading Secrets ---\")\n","load_secrets_from_file()\n","\n","# Load Model and Tokenizer\n","print(f\"\\n--- Loading Model ---\")\n","print(f\"Base model: {BASE_MODEL_PATH}\")\n","tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, padding_side='left')\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"left\"\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    BASE_MODEL_PATH,\n","    torch_dtype=torch.bfloat16,\n","    device_map=\"auto\",\n","    trust_remote_code=True,\n","    use_cache=False,\n",")\n","model.gradient_checkpointing_enable()\n","model.config.pad_token_id = tokenizer.pad_token_id\n","model.config.padding_side = tokenizer.padding_side\n","print(\"✅ Model and tokenizer loaded.\")\n","\n","# Prepare Training Data\n","print(\"\\n--- Preparing Training Data ---\")\n","train_dataset = load_training_data(tokenizer, num_samples=NUM_SAMPLES, seed=RANDOM_SEED)\n","\n","# Initialize Reward Function\n","print(\"\\n--- Initializing Reward Function ---\")\n","reward_fn_instance = ExerciseRewardFunction(\n","    device=\"cuda\",\n","    disabled_scorers=DISABLED_SCORERS,\n","    fluency_use_llm=FLUENCY_USE_LLM,\n","    concurrency_limit=10  # High concurrency for speed\n",")\n","reward_func = create_async_multi_reward(reward_fn_instance, use_openai=True)\n","print(\"✅ Reward function ready.\")\n"]},{"cell_type":"code","source":["# Initialize Trainer\n","print(\"\\n--- Initializing GRPO Trainer ---\")\n","trainer = GRPOTrainer(\n","    model=model,\n","    args=grpo_config,\n","    reward_funcs=reward_func,\n","    train_dataset=train_dataset,\n","    processing_class=tokenizer,\n",")\n","print(\"✅ GRPO Trainer initialized.\")\n","\n","# Start Training\n","print(\"\\n\" + \"=\" * 80)\n","print(\"🔥 TRAINING BEGINS\")\n","print(\"=\" * 80)\n","trainer.train()\n","print(\"\\n\" + \"=\" * 80)\n","print(\"🎉 TRAINING COMPLETE\")\n","print(\"=\" * 80)\n","\n","# Save Final Model\n","print(f\"\\n--- Saving Model ---\")\n","print(f\"Output directory: {OUTPUT_DIR}\")\n","trainer.save_model(OUTPUT_DIR)\n","tokenizer.save_pretrained(OUTPUT_DIR)\n","print(\"✅ Model saved successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"OgdhaHOWO_PS","outputId":"f83c023a-3bfe-4f17-82c0-e03560a6839a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The model is already on multiple devices. Skipping the move to device specified in `args`.\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Initializing GRPO Trainer ---\n","✅ GRPO Trainer initialized.\n","\n","================================================================================\n","🔥 TRAINING BEGINS\n","================================================================================\n"]},{"output_type":"stream","name":"stderr","text":["`generation_config` default values have been modified to match model-specific defaults: {'max_length': 8192}. If this is not desired, please set these values explicitly.\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (54 total requests):\n","      🔵 Gemini: 18/54 (33.3%)\n","      🟢 Openai: 18/54 (33.3%)\n","      ⚡ Groq: 18/54 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (45.4s):\n","   Grammar   : min=0.0, max=60.0, avg=5.0\n","   Coherence : min=0.0, max=100.0, avg=53.5\n","   Topic     : min=6.7, max=100.0, avg=60.5\n","   Quality   : min=10.0, max=66.7, avg=40.8\n","   Diversity : min=20.0, max=100.0, avg=76.9\n","   TOTAL     : min=0.000, max=64.697, avg=24.538\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (45 total requests):\n","      🔵 Gemini: 15/45 (33.3%)\n","      🟢 Openai: 15/45 (33.3%)\n","      ⚡ Groq: 15/45 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (42.6s):\n","   Grammar   : min=0.0, max=100.0, avg=53.5\n","   Coherence : min=0.0, max=100.0, avg=60.8\n","   Topic     : min=12.0, max=100.0, avg=61.3\n","   Quality   : min=10.0, max=50.0, avg=25.5\n","   Diversity : min=12.0, max=80.0, avg=46.5\n","   TOTAL     : min=0.000, max=73.030, avg=19.037\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 17/125 26:02 < 3:07:30, 0.01 it/s, Epoch 0.13/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>5</td>\n","      <td>-0.013000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>-0.030200</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.004200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (45 total requests):\n","      🔵 Gemini: 15/45 (33.3%)\n","      🟢 Openai: 15/45 (33.3%)\n","      ⚡ Groq: 15/45 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (43.4s):\n","   Grammar   : min=0.0, max=90.0, avg=21.8\n","   Coherence : min=0.0, max=100.0, avg=40.3\n","   Topic     : min=0.0, max=100.0, avg=62.2\n","   Quality   : min=10.0, max=50.0, avg=34.3\n","   Diversity : min=28.3, max=100.0, avg=64.3\n","   TOTAL     : min=0.000, max=65.568, avg=17.582\n"]},{"output_type":"stream","name":"stderr","text":["\rA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (45 total requests):\n","      🔵 Gemini: 15/45 (33.3%)\n","      🟢 Openai: 15/45 (33.3%)\n","      ⚡ Groq: 15/45 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (42.8s):\n","   Grammar   : min=0.0, max=80.0, avg=19.2\n","   Coherence : min=0.0, max=83.3, avg=39.2\n","   Topic     : min=0.0, max=100.0, avg=73.0\n","   Quality   : min=10.0, max=90.0, avg=36.0\n","   Diversity : min=28.3, max=80.0, avg=57.0\n","   TOTAL     : min=0.000, max=66.364, avg=20.813\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (42 total requests):\n","      🔵 Gemini: 14/42 (33.3%)\n","      🟢 Openai: 14/42 (33.3%)\n","      ⚡ Groq: 14/42 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (32.8s):\n","   Grammar   : min=0.0, max=100.0, avg=41.0\n","   Coherence : min=0.0, max=100.0, avg=43.0\n","   Topic     : min=6.7, max=100.0, avg=59.3\n","   Quality   : min=9.0, max=50.0, avg=28.0\n","   Diversity : min=30.0, max=80.0, avg=45.3\n","   TOTAL     : min=0.000, max=61.212, avg=13.270\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (18 total requests):\n","      🔵 Gemini: 6/18 (33.3%)\n","      🟢 Openai: 6/18 (33.3%)\n","      ⚡ Groq: 6/18 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (20.9s):\n","   Grammar   : min=0.0, max=84.0, avg=40.3\n","   Coherence : min=10.0, max=80.0, avg=40.0\n","   Topic     : min=54.0, max=94.0, avg=77.0\n","   Quality   : min=10.0, max=50.0, avg=27.3\n","   Diversity : min=48.0, max=76.0, avg=65.3\n","   TOTAL     : min=0.000, max=71.909, avg=7.465\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (54 total requests):\n","      🔵 Gemini: 18/54 (33.3%)\n","      🟢 Openai: 18/54 (33.3%)\n","      ⚡ Groq: 18/54 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (43.9s):\n","   Grammar   : min=0.0, max=90.0, avg=29.3\n","   Coherence : min=0.0, max=100.0, avg=42.6\n","   Topic     : min=20.0, max=100.0, avg=63.4\n","   Quality   : min=5.0, max=50.0, avg=27.0\n","   Diversity : min=15.0, max=100.0, avg=52.2\n","   TOTAL     : min=0.000, max=67.727, avg=19.753\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (54 total requests):\n","      🔵 Gemini: 18/54 (33.3%)\n","      🟢 Openai: 18/54 (33.3%)\n","      ⚡ Groq: 18/54 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (48.5s):\n","   Grammar   : min=0.0, max=90.0, avg=46.6\n","   Coherence : min=16.7, max=87.5, avg=49.7\n","   Topic     : min=20.0, max=100.0, avg=76.9\n","   Quality   : min=10.0, max=50.0, avg=38.0\n","   Diversity : min=24.0, max=100.0, avg=67.7\n","   TOTAL     : min=0.000, max=66.667, avg=25.272\n"]},{"output_type":"stream","name":"stderr","text":["\rA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (45 total requests):\n","      🔵 Gemini: 15/45 (33.3%)\n","      🟢 Openai: 15/45 (33.3%)\n","      ⚡ Groq: 15/45 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (37.9s):\n","   Grammar   : min=0.0, max=90.0, avg=18.3\n","   Coherence : min=0.0, max=100.0, avg=59.2\n","   Topic     : min=10.0, max=100.0, avg=61.6\n","   Quality   : min=5.0, max=51.2, avg=34.8\n","   Diversity : min=20.0, max=100.0, avg=50.7\n","   TOTAL     : min=0.000, max=65.152, avg=12.851\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (45 total requests):\n","      🔵 Gemini: 15/45 (33.3%)\n","      🟢 Openai: 15/45 (33.3%)\n","      ⚡ Groq: 15/45 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (38.6s):\n","   Grammar   : min=0.0, max=92.0, avg=30.3\n","   Coherence : min=0.0, max=100.0, avg=35.7\n","   Topic     : min=0.0, max=100.0, avg=70.8\n","   Quality   : min=10.0, max=50.0, avg=31.5\n","   Diversity : min=12.0, max=70.0, avg=55.6\n","   TOTAL     : min=0.000, max=61.455, avg=18.130\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (45 total requests):\n","      🔵 Gemini: 15/45 (33.3%)\n","      🟢 Openai: 15/45 (33.3%)\n","      ⚡ Groq: 15/45 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (42.6s):\n","   Grammar   : min=0.0, max=90.0, avg=49.3\n","   Coherence : min=0.0, max=100.0, avg=60.9\n","   Topic     : min=13.3, max=100.0, avg=76.8\n","   Quality   : min=10.0, max=50.0, avg=31.6\n","   Diversity : min=24.0, max=80.0, avg=52.7\n","   TOTAL     : min=0.000, max=76.364, avg=18.359\n"]},{"output_type":"stream","name":"stderr","text":["\rA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (42 total requests):\n","      🔵 Gemini: 14/42 (33.3%)\n","      🟢 Openai: 14/42 (33.3%)\n","      ⚡ Groq: 14/42 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (37.8s):\n","   Grammar   : min=0.0, max=57.5, avg=15.2\n","   Coherence : min=0.0, max=100.0, avg=56.2\n","   Topic     : min=20.0, max=100.0, avg=76.6\n","   Quality   : min=10.0, max=50.0, avg=39.3\n","   Diversity : min=15.0, max=80.0, avg=60.0\n","   TOTAL     : min=0.000, max=64.432, avg=17.541\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (27 total requests):\n","      🔵 Gemini: 9/27 (33.3%)\n","      🟢 Openai: 9/27 (33.3%)\n","      ⚡ Groq: 9/27 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (22.3s):\n","   Grammar   : min=0.0, max=90.0, avg=37.2\n","   Coherence : min=0.0, max=75.0, avg=34.7\n","   Topic     : min=10.0, max=86.7, avg=44.7\n","   Quality   : min=10.0, max=50.0, avg=25.6\n","   Diversity : min=35.0, max=100.0, avg=62.2\n","   TOTAL     : min=0.000, max=70.606, avg=10.872\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (27 total requests):\n","      🔵 Gemini: 9/27 (33.3%)\n","      🟢 Openai: 9/27 (33.3%)\n","      ⚡ Groq: 9/27 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (24.7s):\n","   Grammar   : min=0.0, max=90.0, avg=57.0\n","   Coherence : min=0.0, max=100.0, avg=52.7\n","   Topic     : min=60.0, max=100.0, avg=92.6\n","   Quality   : min=10.0, max=50.0, avg=28.6\n","   Diversity : min=53.3, max=88.0, avg=72.0\n","   TOTAL     : min=0.000, max=84.091, avg=15.478\n"]},{"output_type":"stream","name":"stderr","text":["\rA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (33 total requests):\n","      🔵 Gemini: 11/33 (33.3%)\n","      🟢 Openai: 11/33 (33.3%)\n","      ⚡ Groq: 11/33 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (26.4s):\n","   Grammar   : min=0.0, max=60.0, avg=15.6\n","   Coherence : min=20.0, max=100.0, avg=48.6\n","   Topic     : min=10.0, max=93.3, avg=56.5\n","   Quality   : min=10.0, max=51.7, avg=39.8\n","   Diversity : min=12.0, max=86.7, avg=51.4\n","   TOTAL     : min=0.000, max=63.182, avg=9.521\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (36 total requests):\n","      🔵 Gemini: 12/36 (33.3%)\n","      🟢 Openai: 12/36 (33.3%)\n","      ⚡ Groq: 12/36 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (29.4s):\n","   Grammar   : min=0.0, max=90.0, avg=35.8\n","   Coherence : min=0.0, max=100.0, avg=59.2\n","   Topic     : min=20.0, max=100.0, avg=77.2\n","   Quality   : min=8.3, max=66.7, avg=41.7\n","   Diversity : min=40.0, max=86.7, avg=61.7\n","   TOTAL     : min=0.000, max=64.848, avg=15.804\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (36 total requests):\n","      🔵 Gemini: 12/36 (33.3%)\n","      🟢 Openai: 12/36 (33.3%)\n","      ⚡ Groq: 12/36 (33.3%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (28.0s):\n","   Grammar   : min=0.0, max=90.0, avg=24.6\n","   Coherence : min=0.0, max=100.0, avg=38.2\n","   Topic     : min=13.3, max=100.0, avg=62.6\n","   Quality   : min=10.0, max=50.0, avg=28.6\n","   Diversity : min=28.3, max=80.0, avg=50.8\n","   TOTAL     : min=0.000, max=58.295, avg=12.186\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (45 total requests):\n","      🟢 Openai: 18/45 (40.0%)\n","      ⚡ Groq: 18/45 (40.0%)\n","      🔵 Gemini: 9/45 (20.0%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (69.7s):\n","   Grammar   : min=0.0, max=90.0, avg=48.1\n","   Coherence : min=0.0, max=90.0, avg=43.1\n","   Topic     : min=46.7, max=100.0, avg=83.3\n","   Quality   : min=5.0, max=50.0, avg=28.0\n","   Diversity : min=33.3, max=100.0, avg=64.9\n","   TOTAL     : min=0.000, max=82.182, avg=27.440\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (24 total requests):\n","      🟢 Openai: 12/24 (50.0%)\n","      ⚡ Groq: 12/24 (50.0%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (86.9s):\n","   Grammar   : min=50.0, max=50.0, avg=50.0\n","   Coherence : min=0.0, max=83.3, avg=30.5\n","   Topic     : min=16.0, max=100.0, avg=59.0\n","   Quality   : min=10.0, max=50.0, avg=32.1\n","   Diversity : min=15.0, max=100.0, avg=54.2\n","   TOTAL     : min=0.000, max=68.939, avg=13.411\n"]},{"output_type":"stream","name":"stderr","text":["\rA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (28 total requests):\n","      ⚡ Groq: 15/28 (53.6%)\n","      🟢 Openai: 13/28 (46.4%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (96.1s):\n","   Grammar   : min=50.0, max=50.0, avg=50.0\n","   Coherence : min=0.0, max=87.5, avg=38.3\n","   Topic     : min=16.0, max=100.0, avg=61.9\n","   Quality   : min=10.0, max=50.0, avg=30.2\n","   Diversity : min=30.0, max=85.0, avg=54.1\n","   TOTAL     : min=0.000, max=66.727, avg=15.853\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (18 total requests):\n","      🟢 Openai: 9/18 (50.0%)\n","      ⚡ Groq: 9/18 (50.0%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (51.9s):\n","   Grammar   : min=50.0, max=50.0, avg=50.0\n","   Coherence : min=0.0, max=100.0, avg=64.8\n","   Topic     : min=36.7, max=96.7, avg=64.1\n","   Quality   : min=10.0, max=66.7, avg=38.5\n","   Diversity : min=30.0, max=80.0, avg=50.0\n","   TOTAL     : min=0.000, max=47.576, avg=7.294\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","⏳ Step 1/3: Parsing 36 JSON completions...\n"]},{"output_type":"stream","name":"stderr","text":["                                                    "]},{"output_type":"stream","name":"stdout","text":["⏳ Step 2/3: Scoring 36 completions with batched reward function...\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["\n","   📊 Model Usage Distribution (38 total requests):\n","      🟢 Openai: 19/38 (50.0%)\n","      ⚡ Groq: 19/38 (50.0%)\n","⏳ Step 3/3: Computing CPU-bound rewards and aggregating results...\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","🎯 Reward calculation complete (104.8s):\n","   Grammar   : min=50.0, max=50.0, avg=50.0\n","   Coherence : min=0.0, max=100.0, avg=56.2\n","   Topic     : min=20.0, max=100.0, avg=74.6\n","   Quality   : min=5.0, max=62.5, avg=33.5\n","   Diversity : min=25.3, max=86.7, avg=50.5\n","   TOTAL     : min=0.000, max=79.811, avg=25.124\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a749819e3451414ebecd80adfceb88c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_925b645e39b74e55aeb0d781e28bf0fb","IPY_MODEL_547ae1e792b647a9ad248387071c17ac","IPY_MODEL_66d673a3cd204eb6aa59d0b41d8c0d75"],"layout":"IPY_MODEL_feec6650cb86433c96d51603fcd5b94f"}},"925b645e39b74e55aeb0d781e28bf0fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c7f27abb2ac4f199ddc7d416da5ddb6","placeholder":"​","style":"IPY_MODEL_545119c7d2b94d6ca75bb067f082d125","value":"Loading checkpoint shards: 100%"}},"547ae1e792b647a9ad248387071c17ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_873742b3a85d42219253b60c89826d0e","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_904c5db8dd7d4638ae46fc5fdf203ee6","value":4}},"66d673a3cd204eb6aa59d0b41d8c0d75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88b07741ab714d53a6506b81348c525d","placeholder":"​","style":"IPY_MODEL_6ab9cbc54ba140da853e2ed97c362b75","value":" 4/4 [00:12&lt;00:00,  2.62s/it]"}},"feec6650cb86433c96d51603fcd5b94f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c7f27abb2ac4f199ddc7d416da5ddb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"545119c7d2b94d6ca75bb067f082d125":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"873742b3a85d42219253b60c89826d0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"904c5db8dd7d4638ae46fc5fdf203ee6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88b07741ab714d53a6506b81348c525d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ab9cbc54ba140da853e2ed97c362b75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}