{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2033,"status":"ok","timestamp":1761062460625,"user":{"displayName":"Ariel Katzir","userId":"13010007500212358071"},"user_tz":-60},"id":"cgglLZveCxEf","outputId":"1cbf268d-3a26-4348-fada-b4a51d1943d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks/italian_teacher\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Navigate to project\n","%cd /content/drive/MyDrive/Colab\\ Notebooks/italian_teacher"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22236,"status":"ok","timestamp":1761062482859,"user":{"displayName":"Ariel Katzir","userId":"13010007500212358071"},"user_tz":-60},"id":"nRsfgtcKC3v-","outputId":"6f28117c-0927-436d-a30f-af71009ef47a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting it-core-news-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.8.0/it_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('it_core_news_sm')\n","\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}],"source":["# Install dependencies\n","!pip install -q transformers trl accelerate peft datasets spacy sentence-transformers bitsandbytes json5 openai tqdm nest_asyncio\n","!python -m spacy download it_core_news_sm"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":20517,"status":"ok","timestamp":1761062503378,"user":{"displayName":"Ariel Katzir","userId":"13010007500212358071"},"user_tz":-60},"id":"V4pamFwuDOBv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"421ddf5b-fc14-4495-ae2c-ba74afa879cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- 1. SETTING UP ENVIRONMENT ---\n","‚úÖ Added '/content/drive/MyDrive/Colab Notebooks/italian_teacher/src' to Python path\n","‚úÖ Successfully imported reward function components.\n"]}],"source":["# ==============================================================================\n","# CELL 1: SETUP AND IMPORTS\n","# ==============================================================================\n","import asyncio\n","import os\n","import time\n","import sys\n","from pathlib import Path\n","import torch\n","import traceback\n","import httpx\n","import random\n","import json\n","\n","print(\"--- 1. SETTING UP ENVIRONMENT ---\")\n","\n","# --- Add project to Python path ---\n","# Assumes notebook is in the root of the 'italian_teacher' project\n","try:\n","    project_root = Path.cwd()\n","    src_path = project_root / \"src\"\n","    if str(src_path) not in sys.path:\n","        sys.path.insert(0, str(src_path))\n","    print(f\"‚úÖ Added '{src_path}' to Python path\")\n","\n","    from rl.reward_function.reward_function_modular import ExerciseRewardFunction\n","    from rl.reward_function.scorers.base_llm_scorer import BaseLLMScorer\n","    from rl.reward_function.scorers.grammar_scorer import GrammarScorer\n","    from rl.reward_function.scorers.cefr_scorer import CEFRScorer\n","    from rl.reward_function.scorers.coherence_scorer import CoherenceScorer\n","    print(\"‚úÖ Successfully imported reward function components.\")\n","\n","except ImportError as e:\n","    print(\"\\n‚ùå FAILED TO IMPORT PROJECT MODULES.\")\n","    print(\"Please ensure that your 'src' directory is accessible from this notebook.\")\n","    print(f\"Error: {e}\")\n","    raise"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30948,"status":"ok","timestamp":1761062534327,"user":{"displayName":"Ariel Katzir","userId":"13010007500212358071"},"user_tz":-60},"id":"lWP0FlPmDS4m","outputId":"a2c643f1-51a0-453f-8a22-b89f1ad8287b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your OpenAI API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"]}],"source":["import os\n","from getpass import getpass\n","\n","# You can enable/disable OpenAI here:\n","USE_OPENAI = True  # Set to False for faster training without OpenAI\n","\n","OPENAI_API_KEY = getpass(\"Enter your OpenAI API key: \")\n","os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"]},{"cell_type":"code","source":["\n","\n","# ==============================================================================\n","# CELL 2: STRESS TEST CLASSES AND MOCK DATA\n","# ==============================================================================\n","\n","print(\"\\n--- 2. DEFINING STRESS TEST COMPONENTS ---\")\n","\n","class TestState:\n","    \"\"\"A simple, thread-safe class to hold shared test state like error counts.\"\"\"\n","    def __init__(self):\n","        self.timeout_errors = 0\n","        self.lock = asyncio.Lock()\n","\n","    async def increment_errors(self):\n","        async with self.lock:\n","            self.timeout_errors += 1\n","\n","def create_stress_test_scorer(ScorerClass, test_state):\n","    \"\"\"A factory to create StressTest versions of our LLM scorers.\"\"\"\n","    class StressTestScorer(ScorerClass):\n","        def __init__(self, *args, **kwargs):\n","            # Pass original args to the parent, but don't re-print the init message\n","            # by temporarily redirecting stdout\n","            original_stdout = sys.stdout\n","            sys.stdout = open(os.devnull, 'w')\n","            super().__init__(*args, **kwargs)\n","            sys.stdout = original_stdout\n","            self.test_state = test_state\n","\n","        async def score_batch(self, exercises, request, semaphore=None):\n","            try:\n","                # Call the original, real score_batch method\n","                return await super().score_batch(exercises, request, semaphore)\n","            except (httpx.TimeoutException, asyncio.TimeoutError) as e:\n","                # If it times out, increment the shared error counter\n","                await self.test_state.increment_errors()\n","                print(f\"  üî• TIMEOUT DETECTED in {self.name} scorer.\")\n","                # Return a neutral/penalty score for each exercise in the batch\n","                return [(5.0, [f\"{self.name} timed out\"])] * len(exercises)\n","\n","    return StressTestScorer\n","\n","# --- Mock Data Generation ---\n","NUM_SAMPLES = 64  # A good number to stress the API\n","EXERCISES_PER_SAMPLE = 3\n","print(f\"Generating {NUM_SAMPLES} mock data samples ({EXERCISES_PER_SAMPLE} exercises each)...\")\n","\n","mock_exercises_batch = [\n","    {\"type\": \"fill_in_blank\", \"question\": \"Ieri, io ___ (andare) al cinema.\", \"correct_answer\": \"sono andato\"},\n","    {\"type\": \"translation\", \"question\": \"The cat is on the table.\", \"correct_answer\": \"Il gatto √® sul tavolo.\"},\n","    {\"type\": \"multiple_choice\", \"question\": \"Noi ___ la pizza.\", \"correct_answer\": \"mangiamo\", \"options\": [\"mangi\", \"mangia\", \"mangiamo\", \"mangiano\"]}\n","]\n","mock_request = {\"topic\": \"Daily Life\", \"level\": \"A2\", \"grammar_focus\": \"past_tense and present_tense\"}\n","\n","print(\"‚úÖ Mock data ready.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QzFRxHfBTr_A","executionInfo":{"status":"ok","timestamp":1761062534746,"user_tz":-60,"elapsed":413,"user":{"displayName":"Ariel Katzir","userId":"13010007500212358071"}},"outputId":"b67df388-d57d-46ee-ce77-564c8c690a55"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- 2. DEFINING STRESS TEST COMPONENTS ---\n","Generating 64 mock data samples (3 exercises each)...\n","‚úÖ Mock data ready.\n"]}]},{"cell_type":"code","source":["# ==============================================================================\n","# CELL 3: CORE TEST FUNCTION (Corrected)\n","# ==============================================================================\n","\n","print(\"\\n--- 3. DEFINING CORE TEST LOGIC ---\")\n","\n","async def run_stress_test(concurrency_limit: int, client_timeout: int):\n","    \"\"\"\n","    Runs a single stress test with a given concurrency limit and timeout.\n","    \"\"\"\n","    print(\"-\" * 80)\n","    print(f\"üöÄ Starting Test: Concurrency = {concurrency_limit}, Client Timeout = {client_timeout}s\")\n","    print(\"-\" * 80)\n","\n","    # This object will be shared across all scorer instances to count errors\n","    test_state = TestState()\n","\n","    # Create a temporary reward function instance for this test run\n","    # This also loads the spaCy model into `reward_fn.nlp` for the scorers that still use it.\n","    reward_fn = ExerciseRewardFunction()\n","\n","    # --- Create and Inject Test Scorers ---\n","    # This is the core of the new approach: we replace the real scorers\n","    # with our special test versions that can count timeouts.\n","    StressTestGrammarScorer = create_stress_test_scorer(GrammarScorer, test_state)\n","    StressTestCEFRScorer = create_stress_test_scorer(CEFRScorer, test_state)\n","    StressTestCoherenceScorer = create_stress_test_scorer(CoherenceScorer, test_state)\n","\n","    # Correctly instantiate each test scorer.\n","    # The LLM-based scorers no longer need the `nlp` object.\n","    reward_fn.scorers['grammar'] = StressTestGrammarScorer()\n","    reward_fn.scorers['cefr'] = StressTestCEFRScorer()\n","    reward_fn.scorers['coherence'] = StressTestCoherenceScorer()\n","\n","    # The semaphore controls the total number of concurrent requests to the OpenAI API\n","    semaphore = asyncio.Semaphore(concurrency_limit)\n","\n","    start_time = time.time()\n","    try:\n","        # Create a list of tasks. Each task scores one batch of mock exercises.\n","        # This simulates the I/O-bound part of the main reward function.\n","        io_tasks = []\n","        for _ in range(NUM_SAMPLES):\n","            # For each \"sample\", we simulate scoring the batch of exercises with each LLM scorer.\n","            io_tasks.append(reward_fn.scorers['grammar'].score_batch(mock_exercises_batch, mock_request, semaphore))\n","            io_tasks.append(reward_fn.scorers['cefr'].score_batch(mock_exercises_batch, mock_request, semaphore))\n","            io_tasks.append(reward_fn.scorers['coherence'].score_batch(mock_exercises_batch, mock_request, semaphore))\n","\n","        # Run all tasks concurrently\n","        results = await asyncio.gather(*io_tasks, return_exceptions=True)\n","        elapsed = time.time() - start_time\n","\n","        # Check for any unexpected exceptions that weren't timeouts\n","        for result in results:\n","            if isinstance(result, Exception):\n","                print(f\"  üö® Unexpected error during gather: {result}\")\n","                traceback.print_exception(type(result), result, result.__traceback__)\n","\n","        print(\"\\n--- Test Results ---\")\n","        print(f\"‚úÖ Test completed.\")\n","        print(f\"‚è±Ô∏è  Total Time: {elapsed:.2f} seconds\")\n","        print(f\"üì¶ Batches Processed: {NUM_SAMPLES}\")\n","        print(f\"üî• Total API Calls Simulated: {len(io_tasks)}\")\n","        print(f\"‚ùå Timeout Errors Detected: {test_state.timeout_errors}\")\n","\n","        avg_time_per_batch = elapsed / NUM_SAMPLES if NUM_SAMPLES else 0\n","        print(f\"‚öôÔ∏è  Avg Time/Sample Batch: {avg_time_per_batch:.2f} seconds\")\n","\n","        if test_state.timeout_errors > 0:\n","            print(f\"\\n‚ö†Ô∏è WARNING: Encountered {test_state.timeout_errors} timeout errors. The concurrency limit of {concurrency_limit} is likely too high.\")\n","        else:\n","            print(f\"\\nüëç SUCCESS: No timeout errors. Concurrency limit of {concurrency_limit} appears stable.\")\n","\n","    except Exception:\n","        elapsed = time.time() - start_time\n","        print(f\"\\n‚ùå TEST FAILED after {elapsed:.2f} seconds.\")\n","        print(\"An unexpected error occurred during the test:\")\n","        traceback.print_exc()\n","\n","    return test_state.timeout_errors, elapsed\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JLwKhVWgTuYi","executionInfo":{"status":"ok","timestamp":1761062534817,"user_tz":-60,"elapsed":70,"user":{"displayName":"Ariel Katzir","userId":"13010007500212358071"}},"outputId":"2da05b6b-9d4b-4f9a-b87b-c713a7a2c571"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- 3. DEFINING CORE TEST LOGIC ---\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":258443,"status":"ok","timestamp":1761062793270,"user":{"displayName":"Ariel Katzir","userId":"13010007500212358071"},"user_tz":-60},"id":"CdIqiDaPCoIB","outputId":"e698b8c3-60ca-499c-b47e-79b6ff90e4f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Applied nest_asyncio patch for notebook compatibility.\n","\n","================================================================================\n","üî¨ RUNNING STRESS TEST SUITE\n","================================================================================\n","--------------------------------------------------------------------------------\n","üöÄ Starting Test: Concurrency = 5, Client Timeout = 60s\n","--------------------------------------------------------------------------------\n","Loading spaCy model: it_core_news_sm...\n","‚úÖ spaCy model loaded\n","Reward function will use device: cpu\n","Initializing scorers...\n","  ‚úÖ LLM scoring enabled for cefr_alignment (batch size: 10)\n","  ‚úÖ LLM fluency checking enabled (OpenAI API)\n","  ‚úÖ LLM scoring enabled for grammar_correctness (batch size: 10)\n","  ‚úÖ LLM scoring enabled for coherence (batch size: 10)\n","Loading sentence transformer for topic similarity...\n","‚úÖ Sentence transformer loaded in cpu\n","  ‚úÖ LLM topic checking enabled (OpenAI API)\n","‚úÖ Reward function initialized with 8 professional scorers (including coherence)\n","\n","--- Test Results ---\n","‚úÖ Test completed.\n","‚è±Ô∏è  Total Time: 89.98 seconds\n","üì¶ Batches Processed: 64\n","üî• Total API Calls Simulated: 192\n","‚ùå Timeout Errors Detected: 0\n","‚öôÔ∏è  Avg Time/Sample Batch: 1.41 seconds\n","\n","üëç SUCCESS: No timeout errors. Concurrency limit of 5 appears stable.\n","--------------------------------------------------------------------------------\n","üöÄ Starting Test: Concurrency = 10, Client Timeout = 60s\n","--------------------------------------------------------------------------------\n","Loading spaCy model: it_core_news_sm...\n","‚úÖ spaCy model loaded\n","Reward function will use device: cpu\n","Initializing scorers...\n","  ‚úÖ LLM scoring enabled for cefr_alignment (batch size: 10)\n","  ‚úÖ LLM fluency checking enabled (OpenAI API)\n","  ‚úÖ LLM scoring enabled for grammar_correctness (batch size: 10)\n","  ‚úÖ LLM scoring enabled for coherence (batch size: 10)\n","Loading sentence transformer for topic similarity...\n","‚úÖ Sentence transformer loaded in cpu\n","  ‚úÖ LLM topic checking enabled (OpenAI API)\n","‚úÖ Reward function initialized with 8 professional scorers (including coherence)\n","\n","--- Test Results ---\n","‚úÖ Test completed.\n","‚è±Ô∏è  Total Time: 48.40 seconds\n","üì¶ Batches Processed: 64\n","üî• Total API Calls Simulated: 192\n","‚ùå Timeout Errors Detected: 0\n","‚öôÔ∏è  Avg Time/Sample Batch: 0.76 seconds\n","\n","üëç SUCCESS: No timeout errors. Concurrency limit of 10 appears stable.\n","--------------------------------------------------------------------------------\n","üöÄ Starting Test: Concurrency = 20, Client Timeout = 60s\n","--------------------------------------------------------------------------------\n","Loading spaCy model: it_core_news_sm...\n","‚úÖ spaCy model loaded\n","Reward function will use device: cpu\n","Initializing scorers...\n","  ‚úÖ LLM scoring enabled for cefr_alignment (batch size: 10)\n","  ‚úÖ LLM fluency checking enabled (OpenAI API)\n","  ‚úÖ LLM scoring enabled for grammar_correctness (batch size: 10)\n","  ‚úÖ LLM scoring enabled for coherence (batch size: 10)\n","Loading sentence transformer for topic similarity...\n","‚úÖ Sentence transformer loaded in cpu\n","  ‚úÖ LLM topic checking enabled (OpenAI API)\n","‚úÖ Reward function initialized with 8 professional scorers (including coherence)\n","\n","--- Test Results ---\n","‚úÖ Test completed.\n","‚è±Ô∏è  Total Time: 28.07 seconds\n","üì¶ Batches Processed: 64\n","üî• Total API Calls Simulated: 192\n","‚ùå Timeout Errors Detected: 0\n","‚öôÔ∏è  Avg Time/Sample Batch: 0.44 seconds\n","\n","üëç SUCCESS: No timeout errors. Concurrency limit of 20 appears stable.\n","--------------------------------------------------------------------------------\n","üöÄ Starting Test: Concurrency = 40, Client Timeout = 60s\n","--------------------------------------------------------------------------------\n","Loading spaCy model: it_core_news_sm...\n","‚úÖ spaCy model loaded\n","Reward function will use device: cpu\n","Initializing scorers...\n","  ‚úÖ LLM scoring enabled for cefr_alignment (batch size: 10)\n","  ‚úÖ LLM fluency checking enabled (OpenAI API)\n","  ‚úÖ LLM scoring enabled for grammar_correctness (batch size: 10)\n","  ‚úÖ LLM scoring enabled for coherence (batch size: 10)\n","Loading sentence transformer for topic similarity...\n","‚úÖ Sentence transformer loaded in cpu\n","  ‚úÖ LLM topic checking enabled (OpenAI API)\n","‚úÖ Reward function initialized with 8 professional scorers (including coherence)\n","\n","--- Test Results ---\n","‚úÖ Test completed.\n","‚è±Ô∏è  Total Time: 70.57 seconds\n","üì¶ Batches Processed: 64\n","üî• Total API Calls Simulated: 192\n","‚ùå Timeout Errors Detected: 0\n","‚öôÔ∏è  Avg Time/Sample Batch: 1.10 seconds\n","\n","üëç SUCCESS: No timeout errors. Concurrency limit of 40 appears stable.\n","\n","================================================================================\n","üìä FINAL ANALYSIS & RECOMMENDATION\n","================================================================================\n","Concurrency Level | Timeout Errors | Total Time (s)\n","------------------|----------------|---------------\n","5                 | 0              | 89.98         \n","10                | 0              | 48.40         \n","20                | 0              | 28.07         \n","40                | 0              | 70.57         \n","\n","‚úÖ Recommendation: Your maximum stable concurrency limit appears to be around 40.\n","   Set `openai_batch_size = 40` in your training script for the best balance of speed and stability.\n"]}],"source":["\n","\n","async def main():\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üî¨ RUNNING STRESS TEST SUITE\")\n","    print(\"=\"*80)\n","\n","    # Define the concurrency levels you want to test\n","    concurrency_levels = [5, 10, 20, 40]\n","    results = {}\n","\n","    for level in concurrency_levels:\n","        errors, elapsed = await run_stress_test(concurrency_limit=level, client_timeout=60)\n","        results[level] = (errors, elapsed)\n","        # Add a small delay between tests to let any network/API issues settle\n","        await asyncio.sleep(2)\n","\n","    # --- Final Analysis ---\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üìä FINAL ANALYSIS & RECOMMENDATION\")\n","    print(\"=\"*80)\n","\n","    print(\"Concurrency Level | Timeout Errors | Total Time (s)\")\n","    print(\"------------------|----------------|---------------\")\n","    for level, (errors, elapsed) in results.items():\n","        print(f\"{level:<17} | {errors:<14} | {elapsed:<14.2f}\")\n","\n","    stable_limit = 0\n","    for level, (errors, elapsed) in results.items():\n","        if errors == 0:\n","            stable_limit = level\n","        else:\n","            # The first level with errors is the breaking point\n","            break\n","\n","    if stable_limit > 0:\n","        print(f\"\\n‚úÖ Recommendation: Your maximum stable concurrency limit appears to be around {stable_limit}.\")\n","        print(f\"   Set `openai_batch_size = {stable_limit}` in your training script for the best balance of speed and stability.\")\n","    else:\n","        print(\"\\n‚ö†Ô∏è Warning: Timeouts occurred even at the lowest tested concurrency level.\")\n","        print(\"   This may indicate a very strict rate limit on your OpenAI account or a network issue.\")\n","        print(\"   Try setting `openai_batch_size` to a lower value like 2 or 4 in your training script.\")\n","\n","# --- Run the main async function ---\n","# Using nest_asyncio to allow running asyncio.run() in a notebook\n","try:\n","    import nest_asyncio\n","    nest_asyncio.apply()\n","    print(\"\\nApplied nest_asyncio patch for notebook compatibility.\")\n","except ImportError:\n","    pass\n","\n","# This is the entry point that kicks off the entire test suite.\n","asyncio.run(main())\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}